{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e69cbaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_absolute_percentage_error, mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10829686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/Rumah.comdataset_v4.csv\")\n",
    "df = df.drop(columns=['Property Link', 'ID'])\n",
    "df['Listing Area'] = df['Listing Area'].str.replace(' mÂ²', '')\n",
    "df = df.astype({'Listing Area':'int64'})\n",
    "#Print the shape of the dataset before removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "273ac6e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12886, 7)\n"
     ]
    }
   ],
   "source": [
    "#Before we start, perform outlier detection and removal (removing all rows with outlier values) for numerical columns\n",
    "outliers = pd.DataFrame()\n",
    "\n",
    "\n",
    "numerical_cols = [cname for cname in df.columns if df[cname].dtype in ['int64', 'float64']]\n",
    "#Keep removing outliers until there are no more outliers (run the loop 5 times)\n",
    "for i in range(10):\n",
    "    #Check if there are any outliers\n",
    "    for col in numerical_cols:\n",
    "        # Perform outlier detection using Interquartile Range\n",
    "        Q1 = df[col].quantile(0.25)\n",
    "        Q3 = df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "#         # Before removing outliers, put the outliers in a separate dataframe\n",
    "#         outliers = outliers.append(df[(df[col] < Q1 - 1.5*IQR) | (df[col] > Q3 + 1.5*IQR)])\n",
    "        # Remove outliers\n",
    "        df = df[(df[col] >= Q1 - 1.5*IQR) & (df[col] <= Q3 + 1.5*IQR)]\n",
    "\n",
    "\n",
    "\n",
    "#Print the shape of the dataset after outlier removal\n",
    "index1 = df[df.Price <= 100000000].index\n",
    "df = df.drop(index1)\n",
    "\n",
    "index2 = df[df['Listing Area'] <= 21].index\n",
    "df = df.drop(index2)\n",
    "\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f7cbb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.to_csv(\"../data/Rumah.comdataset_v4_modified.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca5c0312",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.Price\n",
    "X = df.drop(['Price'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8c6049d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, \n",
    "                                                            train_size=0.8, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93e14209",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df = pd.concat([X_valid_full, y_valid], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "848debd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"../data/test_case.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4298684a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([X_train_full, y_train], axis=1)\n",
    "train_df.to_csv(\"../data/train_case.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8455e64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Jakarta Division'], ['Street Address', 'Certificate'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "low_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() < 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "high_cardinality_cols = [cname for cname in X_train_full.columns if X_train_full[cname].nunique() >= 10 and \n",
    "                        X_train_full[cname].dtype == \"object\"]\n",
    "low_cardinality_cols, high_cardinality_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eca2feab",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = [cname for cname in X_train_full.columns if X_train_full[cname].dtype in ['int64', 'float64']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdcdd3b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cols = low_cardinality_cols + high_cardinality_cols+ numerical_cols\n",
    "X_train = X_train_full[my_cols].copy()\n",
    "X_valid = X_valid_full[my_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6c132d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical variables:\n",
      "['Jakarta Division', 'Street Address', 'Certificate']\n"
     ]
    }
   ],
   "source": [
    "# Get list of categorical variables\n",
    "s = (X_train.dtypes == 'object')\n",
    "object_cols = list(s[s].index)\n",
    "\n",
    "print(\"Categorical variables:\")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b307fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32118974156460756\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Make copy to avoid changing original data \n",
    "label_X_train = X_train.copy()\n",
    "label_X_valid = X_valid.copy()\n",
    "\n",
    "# Apply ordinal encoder to each column with categorical data\n",
    "ordinal_encoder = OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1)\n",
    "label_X_train[object_cols] = ordinal_encoder.fit_transform(X_train[object_cols])\n",
    "label_X_valid[object_cols] = ordinal_encoder.transform(X_valid[object_cols])\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model.fit(label_X_train, y_train)\n",
    "preds = model.predict(label_X_valid)\n",
    "mape = mean_absolute_percentage_error(y_valid, preds)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a87212f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "filename = \"../data/random_forest.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(model, open(filename, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d378ad52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32118974156460756\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "loaded_model = pickle.load(open(filename, \"rb\"))\n",
    "\n",
    "# you can use loaded model to compute predictions\n",
    "y_predicted = loaded_model.predict(label_X_valid)\n",
    "mape = mean_absolute_percentage_error(y_valid, y_predicted)\n",
    "print(mape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2ca10377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2582,)\n"
     ]
    }
   ],
   "source": [
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "449a49f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename1 = \"../data/ordinal_encoder.pickle\"\n",
    "\n",
    "# save model\n",
    "pickle.dump(ordinal_encoder, open(filename1, \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181dcab9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
